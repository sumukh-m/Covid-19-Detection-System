{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn\n",
    "from glob import glob\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [224, 224] # feel free to change depending on dataset\n",
    "\n",
    "# training config:\n",
    "epochs = 500\n",
    "batch_size = 32\n",
    "\n",
    "#define paths\n",
    "covid_path = '../data/chest/Chest_COVID'\n",
    "noncovid_path = '../data/chest/Chest_NonCOVID'\n",
    "\n",
    "# Use glob to grab images from path .jpg or jpeg\n",
    "covid_files = glob(covid_path + '/*')\n",
    "noncovid_files = glob(noncovid_path + '/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing Labels\n",
    "covid_labels = []\n",
    "noncovid_labels = []\n",
    "\n",
    "covid_images=[]\n",
    "noncovid_images=[]\n",
    "\n",
    "import cv2 \n",
    "\n",
    "for i in range(len(covid_files)):\n",
    "  image = cv2.imread(covid_files[i])\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  image = cv2.resize(image,(224,224))\n",
    "  image = np.transpose(image, (2, 1, 0))\n",
    "  covid_images.append(image)\n",
    "  covid_labels.append('CT_COVID')\n",
    "\n",
    "for i in range(len(noncovid_files)):\n",
    "  image = cv2.imread(noncovid_files[i])\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  image = cv2.resize(image,(224,224))\n",
    "  image = np.transpose(image, (2, 1, 0))\n",
    "  noncovid_images.append(image)\n",
    "  noncovid_labels.append('CT_NonCOVID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize to interval of [0,1]\n",
    "covid_images = np.array(covid_images) / 255\n",
    "noncovid_images = np.array(noncovid_images) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# split into training and testing\n",
    "covid_x_train, covid_x_test, covid_y_train, covid_y_test = train_test_split(\n",
    "    covid_images, covid_labels, test_size=0.2)\n",
    "noncovid_x_train, noncovid_x_test, noncovid_y_train, noncovid_y_test = train_test_split(\n",
    "    noncovid_images, noncovid_labels, test_size=0.2)\n",
    "\n",
    "\n",
    "X_train = np.concatenate((noncovid_x_train, covid_x_train), axis=0)\n",
    "X_test = np.concatenate((noncovid_x_test, covid_x_test), axis=0)\n",
    "y_train = np.concatenate((noncovid_y_train, covid_y_train), axis=0)\n",
    "y_test = np.concatenate((noncovid_y_test, covid_y_test), axis=0)\n",
    "\n",
    "# make labels into categories - either 0 or 1\n",
    "y_train = LabelBinarizer().fit_transform(y_train)\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "y_test = LabelBinarizer().fit_transform(y_test)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(25088, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "net = Net()\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_train=torch.from_numpy(X_train)\n",
    "yt_train = torch.from_numpy(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_test = torch.from_numpy(X_test)\n",
    "Xt_test= Xt_test.float()\n",
    "yt_test = torch.from_numpy(y_test)\n",
    "yt_test= yt_test.float()\n",
    "Xt_test, yt_test = Xt_test.to(device), yt_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step=1\n",
    "\n",
    "for epoch in range(150):\n",
    "    Xt_train= Xt_train.float()\n",
    "    Xt_train = Xt_train.to(device)\n",
    "    yt_train = yt_train.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    pred = net(Xt_train)\n",
    "    loss = criterion(pred, torch.max(yt_train.long(), 1)[1])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Step {step} ==> loss {loss :.4f} ')\n",
    "    step=step+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = torch.tensor(train_acc_arr, device = 'cpu')\n",
    "test_accuracy = torch.tensor(test_acc_arr, device = 'cpu')\n",
    "\n",
    "epoch_rate = [epoch for epoch in range(128)]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epoch_rate, train_accuracy)\n",
    "plt.plot(epoch_rate, test_accuracy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_epoch_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = net(Xt_train)\n",
    "train_acc = torch.sum(y_pred == yt_train)\n",
    "final_train_acc = train_acc/len(Xt_train)\n",
    "print(final_train_acc.to(\"cpu\").numpy() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = net(Xt_test)\n",
    "train_acc = torch.sum(y_pred == yt_test)\n",
    "final_train_acc = train_acc/len(Xt_test)\n",
    "print(final_train_acc.to(\"cpu\").numpy()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(y_pred == yt_test) #188"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.imgs_path = \"../data/chest/\"\n",
    "        file_list = glob(self.imgs_path + \"*\")\n",
    "        print(file_list)\n",
    "        self.data = []\n",
    "        for class_path in file_list:\n",
    "            class_name = class_path.split(\"\\\\\")[-1]\n",
    "            for img_path in glob(class_path + \"/*\"):\n",
    "                self.data.append([img_path, class_name])\n",
    "        print(len(self.data))\n",
    "        self.class_map = {\"Chest_COVID\" : 0, \"Chest_NonCOVID\": 1}\n",
    "        self.img_dim = (224, 224)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, class_name = self.data[idx]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, self.img_dim)\n",
    "        img = np.array(img) / 255\n",
    "        class_id = self.class_map[class_name]\n",
    "        img_tensor = torch.from_numpy(img)\n",
    "        img_tensor = img_tensor.permute(2, 0, 1)\n",
    "        class_id = torch.tensor(class_id)\n",
    "        return img_tensor, class_id\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    dataset = CustomDataset()\n",
    "    data_loader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set=torch.utils.data.random_split(dataset, [752,188 ])\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(dataloader):\n",
    "    total, correct = 0, 0\n",
    "    for data in dataloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs.float())\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 32\n",
    "train_arr = []\n",
    "test_arr=[]\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    \n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_eval = evaluation(train_loader)\n",
    "    test_eval = evaluation(test_loader)\n",
    "    train_arr.append(train_eval)\n",
    "    test_arr.append(test_eval)\n",
    "    print('Epoch: %d/%d  Train_Acc: %.2f Test_Acc: %.2f' % (epoch+1, max_epochs, train_eval, test_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_rate = [epoch for epoch in range(32)]\n",
    "plt.plot(epoch_rate, train_arr)\n",
    "plt.plot(epoch_rate, test_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test acc: %0.2f, Train acc: %0.2f' % (evaluation(test_loader), evaluation(train_loader)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
